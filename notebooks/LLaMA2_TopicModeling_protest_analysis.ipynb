{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3afe926a",
   "metadata": {},
   "source": [
    "# üìò Protest Topic Modeling using BERTopic + LLaMA 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c385519",
   "metadata": {},
   "source": [
    "\n",
    "## üéØ Objective\n",
    "This notebook applies **BERTopic** combined with **LLaMA 2** for labeling protest topics in the ACLED Iran dataset. \n",
    "The goal is to discover coherent topics and generate human-readable labels and explanations using LLaMA 2 text generation.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab88bfb",
   "metadata": {},
   "source": [
    "## 1. Install and Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ff446b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance, TextGeneration\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b131c1",
   "metadata": {},
   "source": [
    "## 2. Load and Preview Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e9b89ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On 6 February 2025, nurses and health workers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On 6 February 2025, Continental Plateau Oil Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On 5 February 2025, workers at the Telecommuni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On 5 February 2025, investors of Cryptoland Di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On 5 February 2025, landowners at the 33 lands...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               notes\n",
       "0  On 6 February 2025, nurses and health workers ...\n",
       "1  On 6 February 2025, Continental Plateau Oil Co...\n",
       "2  On 5 February 2025, workers at the Telecommuni...\n",
       "3  On 5 February 2025, investors of Cryptoland Di...\n",
       "4  On 5 February 2025, landowners at the 33 lands..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"/home/ubuntu/Capstone_Files/data/ACELD_Iran.csv\", sep=';')\n",
    "df[['notes']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41ee3c8",
   "metadata": {},
   "source": [
    "## 3. Preprocess Protest Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "031d1011",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_notes(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = re.sub(r'\\b(?:on\\s+)?\\d{1,2}\\s+\\w+\\s+\\d{4}\\b', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\b(protest(ed|ing)?|rally|gather(ed|ing)?|demonstration|march|strike|held)\\b', '', text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "df['clean_notes'] = df['notes'].apply(clean_notes)\n",
    "\n",
    "custom_stopwords = {\"october\", \"february\", \"january\", \"may\", \"november\", \"december\", \"april\", \"march\"}\n",
    "stop_words = set(stopwords.words(\"english\")).union(custom_stopwords)\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = simple_preprocess(text, deacc=True)\n",
    "    return [word for word in tokens if word not in stop_words and len(word) > 2]\n",
    "\n",
    "processed_texts = df['clean_notes'].fillna(\"\").apply(preprocess).tolist()\n",
    "docs = [\" \".join(tokens) for tokens in processed_texts]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812c7a30",
   "metadata": {},
   "source": [
    "## 4. Generate Sentence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "578a5c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "084a38ebc54a4318a318fce0f8e0f33d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "embedding_model = SentenceTransformer(\"all-mpnet-base-v2\", device='cuda')\n",
    "embeddings = embedding_model.encode(docs, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12d7178",
   "metadata": {},
   "source": [
    "## 5. UMAP Dimensionality Reduction and HDBSCAN Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4e2f34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.1, metric='cosine', random_state=42)\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=20, min_samples=10, metric='euclidean', prediction_data=True)\n",
    "vectorizer_model = CountVectorizer(ngram_range=(1, 2), stop_words=\"english\", min_df=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962c8a5f",
   "metadata": {},
   "source": [
    "## 6. Load LLaMA 2 Model for Few-Shot Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca911fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b7430aa09941b892d7effec6861717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llama_model_id = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(llama_model_id, trust_remote_code=True)\n",
    "llama_model = AutoModelForCausalLM.from_pretrained(llama_model_id, trust_remote_code=True, device_map=\"auto\", torch_dtype=torch.float16).eval()\n",
    "llama_generator = pipeline(\"text-generation\", model=llama_model, tokenizer=llama_tokenizer, temperature=0.1, max_new_tokens=256, repetition_penalty=1.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dff0f7c",
   "metadata": {},
   "source": [
    "## 7. Prepare Few-Shot Prompt Template for LLaMA 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bff2686",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_prompt = \"\"\"<s>[INST] <<SYS>> You are a helpful, respectful, and honest assistant for identifying the main reason behind each protest topic. <</SYS>>\"\"\"\n",
    "\n",
    "few_shot_examples = \"\"\"\n",
    "I have a topic that contains the following documents:\n",
    "- Retired employees rallied for overdue pension payments and social security benefits.\n",
    "- Elderly workers demonstrated at the national pension office demanding fair treatment.\n",
    "- A crowd of retirees chanted for insurance premium reductions and increased monthly payments.\n",
    "\n",
    "The topic is described by the following keywords: 'retirees, pension, insurance, payment, benefits, elderly, demand, treatment, office'.\n",
    "\n",
    "Based on the information above, please provide:\n",
    "Reason: Frustration over pension and benefit delays.\n",
    "Explanation: Retirees are protesting for delayed pension payments and fairer treatment regarding their benefits.\n",
    "Label: Retiree protests over pension issues\n",
    "\"\"\"\n",
    "\n",
    "main_prompt = \"\"\"\n",
    "[INST]\n",
    "I have a topic that contains the following documents:\n",
    "[DOCUMENTS]\n",
    "The topic is described by the following keywords: '[KEYWORDS]'.\n",
    "\n",
    "Based on the information above, please provide:\n",
    "Reason: The main reason for the protests.\n",
    "Explanation: A brief explanation connecting the documents to the reason.\n",
    "Label: A short, descriptive label for this topic.\n",
    "[/INST]\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = system_prompt + few_shot_examples + main_prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c03c432",
   "metadata": {},
   "source": [
    "## 8. Build BERTopic Model and Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71144f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "\n",
    "representation_model = {\n",
    "    \"KeyBERT\": KeyBERTInspired(),\n",
    "    \"MMR\": MaximalMarginalRelevance(diversity=0.3),\n",
    "    \"LLaMA\": TextGeneration(model=llama_generator, prompt=prompt_template)\n",
    "}\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    calculate_probabilities=True,\n",
    "    language='english',\n",
    "    representation_model=representation_model,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "topics, probs = topic_model.fit_transform(docs, embeddings)\n",
    "topic_model = topic_model.reduce_topics(docs, nr_topics=30)\n",
    "topics, probs = topic_model.transform(docs)\n",
    "df[\"topic\"] = topics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5359c61b",
   "metadata": {},
   "source": [
    "## 9. Evaluate Coherence Score and Topic Diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7635f9",
   "metadata": {},
   "source": [
    "### üìà C_V Coherence Score: What it is\n",
    "\n",
    "The **C_V Coherence Score** evaluates how semantically meaningful and internally consistent a topic is. It combines two important dimensions:\n",
    "\n",
    "- **Co-occurrence Frequency**: How often the top words appear together in the original texts (using a sliding window).\n",
    "- **Semantic Similarity**: How closely related the top words are in meaning, based on cosine similarity of their word embeddings.\n",
    "\n",
    "A **higher C_V score** means:\n",
    "- The topic‚Äôs top words frequently occur together in the texts.\n",
    "- The words are more semantically coherent.\n",
    "\n",
    "The C_V score leverages **Normalized Pointwise Mutual Information (NPMI)** and cosine similarity to assess topic coherence.\n",
    "\n",
    "---\n",
    "\n",
    "### üßÆ Formula (Conceptual)\n",
    "\n",
    "Let:\n",
    "- \\( W = \\{w_1, w_2, \\dots, w_k\\} \\) : the top-k words in a topic\n",
    "- \\( \\text{NPMI}(w_i, w_j) \\) : the Normalized Pointwise Mutual Information between \\( w_i \\) and \\( w_j \\)\n",
    "- \\( \\text{Sim}(w_i, w_j) \\) : the semantic similarity (e.g., cosine similarity) between word embeddings of \\( w_i \\) and \\( w_j \\)\n",
    "\n",
    "Then the C_V score is computed as an **aggregated combination** of:\n",
    "\n",
    "$$\n",
    "\\\\text{C}_V = \\\\frac{1}{|W|^2} \\\\sum_{i,j} \\\\text{NPMI}(w_i, w_j) \\\\times \\\\text{Sim}(w_i, w_j)\n",
    "$$\n",
    "\n",
    "> *Note*: Exact implementation may vary depending on the library used (e.g., Gensim), but the conceptual components remain the same.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d222e228",
   "metadata": {},
   "source": [
    "üìä Topic Diversity (Top2Vec)\n",
    "What it is:\n",
    "\n",
    "Topic Diversity measures how distinct the top words are across all discovered topics. A higher score suggests that each topic captures a unique theme, with less repetition of keywords between topics.\n",
    "\n",
    "For Top2Vec, which automatically identifies the number of topics and generates top keywords per topic based on document embeddings, this metric is useful for evaluating how semantically diverse the topics are.\n",
    "\n",
    "**Formula:**  \n",
    "\n",
    "Let \\( T \\) = number of topics  \n",
    "Let \\( k \\) = number of top words per topic  \n",
    "Let \\( W_t \\) = set of top‚Äëk words for topic \\( t \\)\n",
    "\n",
    "Then, Topic Diversity is calculated as:\n",
    "\n",
    "$$\n",
    "\\text{Diversity} = \\frac{\\left|\\bigcup_{t=1}^{T} W_t\\right|}{T \\times k}\n",
    "$$\n",
    "\n",
    "A value of 1.0 means all topics have completely unique top words (no overlap), while lower values indicate overlapping or redundant topic terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c213503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Coherence Score: 0.735\n",
      "Topic Diversity Score: 0.855\n"
     ]
    }
   ],
   "source": [
    "\n",
    "topic_words = [[word for word, _ in topic_model.get_topic(i)] for i in range(len(topic_model.get_topics())) if topic_model.get_topic(i)]\n",
    "dictionary = Dictionary(processed_texts)\n",
    "coherence_model = CoherenceModel(topics=topic_words, texts=processed_texts, dictionary=dictionary, coherence='c_v')\n",
    "print(f\"CV Coherence Score: {round(coherence_model.get_coherence(), 3)}\")\n",
    "\n",
    "def compute_topic_diversity(model, topk=10):\n",
    "    top_words = [set(word for word, _ in model.get_topic(i)[:topk]) for i in range(len(model.get_topics())) if model.get_topic(i)]\n",
    "    all_words = [word for topic in top_words for word in topic]\n",
    "    return len(set(all_words)) / (topk * len(top_words))\n",
    "\n",
    "print(f\"Topic Diversity Score: {round(compute_topic_diversity(topic_model), 3)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f7c080",
   "metadata": {},
   "source": [
    "## üîç Manual Review of Selected Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "540bde88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 0\n",
      "Label: Worker protests over unpaid salaries\n",
      "Reason: Delays in salary payments.\n",
      "Explanation: Workers from various companies, including Haft Tapeh Sugarcane Company and Greenspace Municipal Workers in Hamidiyeh City, Khuzestan, are protesting due to unpaid salaries that have been accumulated for several months. This highlights the financial difficulties faced by these workers and their employers' failure to address the issue in a timely manner.\n",
      "Representative Documents:\n",
      "- workers haft tapeh sugarcane company located outside shush months unpaid salaries\n",
      "\n",
      "- workers haft tapeh sugarcane company located outside shush months unpaid salaries\n",
      "\n",
      "- greenspace municipal workers hamidiyeh city khuzestan months unpaid wages\n",
      "\n",
      "============================================================\n",
      "\n",
      "Topic 1\n",
      "Label: Iranian retirees protest insurance rate hikes, pension arrears.\n",
      "Reason: Dispute over insurance premium rates and payment of pension arrears.\n",
      "Explanation: Retirees in Iran are protesting against the recent changes in insurance rates and the delay in payment of their pension arrears by the social security organization. They are demanding fair treatment and payment of their dues.\n",
      "Representative Documents:\n",
      "- retirees company iran staged front provincial company central office isfahan city isfahan ongoing dispute company regarding insurance premium rates demand payment pension arrears\n",
      "\n",
      "- retirees company iran staged front provincial company central office ahvaz city khuzestan presumably ongoing dispute recent change insurance rates demanded payment wage arrears\n",
      "\n",
      "- retirees company iran staged front provincial company central office tehran district tehran ongoing dispute recent change insurance rates also demanded payment wage arrears\n",
      "\n",
      "============================================================\n",
      "\n",
      "Topic 2\n",
      "Label: Teacher protests against government salary plan delay\n",
      "Reason: Disagreement with the government's decision to delay or fail to implement a salary ranking plan for teachers in various cities across Iran.\n",
      "Explanation: Teachers in Iran are organizing protests and coordinating councils to express their dissatisfaction with the government's failure to implement a salary ranking plan for educators. Despite efforts to address the issue through collective action, the problem persists, leading to frustration among teachers who feel undervalued and underpaid.\n",
      "Representative Documents:\n",
      "- teachers organized coordinating council teachers syndicates iran education department building khonj city fars failure government implement salary ranking plan teachers\n",
      "\n",
      "- active retired teachers organized coordinating council teachers syndicates iran front education department building bafq city yazd failure government implement salary ranking plan teachers\n",
      "\n",
      "- active retired teachers organized coordinating council teachers syndicates iran front education department building arsanjan city fars failure government implement salary ranking plan teachers\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "topics_to_review = [0, 1, 2]\n",
    "rep_docs = topic_model.get_representative_docs()\n",
    "\n",
    "for tid in topics_to_review:\n",
    "    docs_for_topic = rep_docs.get(tid, [])[:3]\n",
    "    if not docs_for_topic:\n",
    "        continue\n",
    "\n",
    "    topic_keywords = \", \".join([word for word, _ in topic_model.get_topic(tid)[:10]])\n",
    "    doc_snippets = \"\\n\".join([f\"- {doc}\" for doc in docs_for_topic])\n",
    "    filled_prompt = prompt_template.replace(\"[DOCUMENTS]\", doc_snippets).replace(\"[KEYWORDS]\", topic_keywords)\n",
    "\n",
    "    try:\n",
    "        response = llama_generator(filled_prompt, return_full_text=False)\n",
    "        raw_output = response[0][\"generated_text\"].strip()\n",
    "        reason = re.search(r\"Reason:\\s*(.+?)\\n\", raw_output)\n",
    "        explanation = re.search(r\"Explanation:\\s*(.+?)\\n\", raw_output)\n",
    "        label = re.search(r\"Label:\\s*(.+)\", raw_output)\n",
    "\n",
    "        reason = reason.group(1).strip() if reason else \"Not provided\"\n",
    "        explanation = explanation.group(1).strip() if explanation else \"Not provided\"\n",
    "        label = label.group(1).strip() if label else f\"Topic {tid}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting for Topic {tid}: {e}\")\n",
    "        reason, explanation, label = \"Error\", \"Error\", f\"Topic {tid}\"\n",
    "\n",
    "    print(f\"\\nTopic {tid}\")\n",
    "    print(f\"Label: {label}\")\n",
    "    print(f\"Reason: {reason}\")\n",
    "    print(f\"Explanation: {explanation}\")\n",
    "    print(\"Representative Documents:\")\n",
    "    for doc in docs_for_topic:\n",
    "        print(f\"- {doc}\\n\")\n",
    "    print(\"=\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capstone_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
